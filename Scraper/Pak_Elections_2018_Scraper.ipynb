{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from time import sleep\n",
    "from random import randint, randrange\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "header = {'User-Agent':str(ua.firefox)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I used the General Election 2018 Dashboard website to fetch URLs for each constituency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "r = requests.get('https://www.ecp.gov.pk/resultdashboard/ge2018.aspx',headers=header)\n",
    "soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "# From the dashboard page, fetch URLs for all the NA seats\n",
    "na_urls = [i.find('a')['href'][2:].replace(' ','%20')\\\n",
    "           for i in soup.find_all(name='div',attrs={'class':'card card-hover'})\\\n",
    "           if i.find('a') != None]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this page has been taken down for some reason so instead I use a list of constituency numbers and insert this into the URL that holds data for each individual constituency.\n",
    "\n",
    "We leave out NA-60 and NA-103 because elections here were postponed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a list of constituency names to insert into the URLs\n",
    "naSeats = ['NA-' + str(i) for i in np.arange(1,273) if i not in [60,103]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe = []\n",
    "count = 0\n",
    "sleep_between_requests == False\n",
    "\n",
    "for seat in naSeats:\n",
    "    url = 'https://www.ecp.gov.pk/ConstResult.aspx?Const_Id=' + seat + '&type=NA&Election_ID=10070&Election=GENERAL%20ELECTION%2025%20JUL%202018'\n",
    "    print('\\n--- Fetching HTML for Seat # : ' + str(seat))\n",
    "    r = requests.get(url,headers=header)\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        print('--- HTML retrieved. Extracting Data')\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    else:\n",
    "        print('*** Abort. HTML Status Code ' + str(r.status_code))\n",
    "        break\n",
    "    \n",
    "    # Extract seat info and result status\n",
    "    seatInfo = soup.find_all('span',{'id' : 'ContentPlaceHolder2_lblSubHeading'})[0].getText()\n",
    "    seatName = seatInfo[seatInfo.find('(') + 1 : seatInfo.find(')')]\n",
    "    seatStatus = seatInfo[seatInfo.find(')') + 1 : ].strip()\n",
    "    \n",
    "    # Extract voting statistics\n",
    "    stats = soup.find_all('table')[0]\n",
    "    registeredVoters = stats.find('span',{'id': 'ContentPlaceHolder1_lblRegVoters'}).getText()\n",
    "    votesPolled = stats.find('span',{'id': 'ContentPlaceHolder1_lblVotesPolled'}).getText()\n",
    "    validVotes = stats.find('span',{'id': 'ContentPlaceHolder1_lblValidVotes'}).getText()\n",
    "    rejectedVotes = stats.find('span',{'id': 'ContentPlaceHolder1_lblRejVotes'}).getText()\n",
    "    polledToRegisteredRatio = stats.find('span',{'id': 'ContentPlaceHolder1_lblTO'}).getText().replace('%','').strip()\n",
    "    \n",
    "    # Extract voting results\n",
    "    voteCount = soup.find_all('table')[1]\n",
    "    votingResults = []\n",
    "    for i in voteCount.find_all('tr'):\n",
    "        row = i.find_all('p')\n",
    "        if len(row) != 0:\n",
    "            candidateName = row[0].getText()\n",
    "            candidateParty = row[1].getText()\n",
    "            candidateVotes = row[2].getText()\n",
    "            votingDict = {'candidateName' : candidateName,\\\n",
    "                          'candidateParty' : candidateParty,\\\n",
    "                          'candidateVotes' : int(candidateVotes)}\n",
    "            votingResults.append(votingDict)\n",
    "        \n",
    "    data = {'seat' : seat,\\\n",
    "            'seatName' : seatName,\\\n",
    "            'seatStatus' : seatStatus,\\\n",
    "            'registeredVoters' : int(registeredVoters),\\\n",
    "            'votesPolled' : int(votesPolled),\\\n",
    "            'validVotes' : int(validVotes),\\\n",
    "            'rejectedVotes' : int(rejectedVotes),\\\n",
    "            'polledToRegRatio' : float(polledToRegisteredRatio) / 100,\\\n",
    "            'numberOfCandidates' : len(votingResults),\\\n",
    "            'votingResults' : votingResults,\n",
    "            }\n",
    "    \n",
    "    dataframe.append(data)\n",
    "    print('--- ' + seat + ' data addedd succesfully.')\n",
    "    count += 1\n",
    "    \n",
    "    if sleep_between_requests == True:\n",
    "        # Sleep for a few seconds before moving on to the next seat\n",
    "        sleep_seconds = randint(2,10)\n",
    "        print('--- Sleeping For : ', sleep_seconds, ' seconds.\\n')\n",
    "        sleep(sleep_seconds)\n",
    "    \n",
    "print('\\n--- ' + str(count) + ' seats processed.')  \n",
    "print('There should be 270 seats : ', len(dataframe) == 270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ECP website has voting results for NA-39 all wrong. For now, this is the only constituency that has faulty data on the website that I'm aware of but I'm pretty sure there are more. Let me know if you come across any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe[38]['votingResults'] = [\n",
    "    {'candidateName' : 'Muhammad Yaqoob Sheikh', 'candidateParty' : 'Pakistan Tehreek-e-Insaf', 'candidateVotes' : 5511},\n",
    "    {'candidateName' : 'Alhaj Sardar Umar Farooq Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 29},\n",
    "    {'candidateName' : 'Asmat Ullah', 'candidateParty' : 'Independent', 'candidateVotes' : 98},\n",
    "    {'candidateName' : 'Eithesham Ullah Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 5},\n",
    "    {'candidateName' : 'Faisal Karim Kundi', 'candidateParty' : 'Independent', 'candidateVotes' : 20},\n",
    "    {'candidateName' : 'Fazl ur Rehman', 'candidateParty' : 'Muttahida Majlis-e-Amal Pakistan', 'candidateVotes' : 4076},\n",
    "    {'candidateName' : 'Irfan Ullah Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 20},\n",
    "    {'candidateName' : 'Muhammad Aftab Inayat', 'candidateParty' : 'Independent', 'candidateVotes' : 105},\n",
    "    {'candidateName' : 'Muhammad Akbar Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 57},\n",
    "    {'candidateName' : 'Muhammad Amir', 'candidateParty' : 'Independent', 'candidateVotes' : 12},\n",
    "    {'candidateName' : 'Muhammad Maqbool', 'candidateParty' : 'Amun Taraqqi Party', 'candidateVotes' : 23},\n",
    "    {'candidateName' : 'Nurang Khan', 'candidateParty' : 'Pakistan Peoples Party Parliamentarians', 'candidateVotes' : 292},\n",
    "    {'candidateName' : 'Obaid Ur Rehman', 'candidateParty' : 'Independent', 'candidateVotes' : 32},\n",
    "    {'candidateName' : 'Qaizar Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 564},\n",
    "    {'candidateName' : 'Waqar Ahmad Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 98},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will also retrieve voter participation rates, which is also bifurcated by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participationResult = []\n",
    "\n",
    "r = requests.get('https://www.ecp.gov.pk/frmstats.aspx',headers=header)\n",
    "soup = BeautifulSoup(r.text, \"lxml\")\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "for i in rows[1:]: # We don't look at the first row since these are just headers.\n",
    "    row = i.find_all('td')\n",
    "    participationResult.append(\n",
    "        {\n",
    "        'seat' : row[0].getText(),\n",
    "        'femaleTurnout' : float(row[1].getText().replace(' %','')) / 100,\n",
    "        'maleTurnout' : float(row[2].getText().replace(' %','')) / 100,\n",
    "        'totalTurnout' : float(row[3].getText().replace(' %','')) / 100,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "dfParticipation = pd.DataFrame(participationResult)\n",
    "\n",
    "# Fix NA-254 participation\n",
    "dfParticipation.loc[dfParticipation['seat'] == 'NA-254','femaleTurnout'] = 0.2892992355\n",
    "dfParticipation.loc[dfParticipation['seat'] == 'NA-125','femaleTurnout'] = np.nan\n",
    "dfParticipation.loc[dfParticipation['seat'] == 'NA-125','maleTurnout'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataframe)\n",
    "df = df.merge(dfParticipation,on='seat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The voting results is a list of dictionaries contained in the dataframe above. For easier access, we will convert this to it's own dataframe and store it in a CSV as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultsOnlyDataframe = []\n",
    "for i in dataframe:\n",
    "    resultsDict = i['votingResults']\n",
    "    for j in resultsDict:\n",
    "        j['seat'] = i['seat']\n",
    "        j['seatName'] = i['seatName']\n",
    "        resultsOnlyDataframe.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfResultsOnly = pd.DataFrame(resultsOnlyDataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winners & Runner Ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding margins from winners.\n",
    "\n",
    "seat = ''\n",
    "for row in dfResultsOnly.iterrows():\n",
    "    if row[1]['seat'] == seat:\n",
    "        margin = winnerVotes - row[1]['candidateVotes']\n",
    "    else:\n",
    "        winnerVotes = dfResultsOnly[dfResultsOnly['seat'] == row[1]['seat']][['candidateVotes']].max().values[0]\n",
    "        margin = winnerVotes - row[1]['candidateVotes']\n",
    "        seat = row[1]['seat']\n",
    "\n",
    "    dfResultsOnly.loc[row[0],'marginFromWinner'] = int(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Winners & Runner Ups DF & CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "winnerIdx = dfResultsOnly.groupby(by='seat',)[['candidateVotes']].idxmax()\n",
    "winnerResults = dfResultsOnly.iloc[winnerIdx['candidateVotes'].values]\n",
    "\n",
    "runnerUpIdx = dfResultsOnly.groupby(by='seat')['candidateVotes'].nlargest(2).reset_index().groupby('seat').last()['level_1'].values\n",
    "runnerupResults = dfResultsOnly.iloc[runnerUpIdx]\n",
    "\n",
    "winnerResults = winnerResults.drop('marginFromWinner',axis=1)\n",
    "winnerResults = winnerResults.merge(runnerupResults[['seat','marginFromWinner']],on='seat').rename(columns={'marginFromWinner' : 'winMargin'})\n",
    "winnerResults.to_csv('../Data/Election_2018_NA_winnerResults.csv',index=False,encoding='utf-8')\n",
    "runnerupResults.to_csv('../Data/Election_2018_NA_runnerupResults.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the HDI to our election results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Election_2018_NA_Results_Raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HDI = pd.read_csv('../Data/HDI2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seat names and the region names in the HDI do not match up. I'm unaware of HDI data that is listed by electoral constituency so I will do my best to match the seats to the HDI regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use difflib to calculate a difference score between the names of the seats and HDI regions.\n",
    "Difflib uses the Gestalt Approach under the hood for pattern matching. You can read more about it at : http://www.drdobbs.com/database/pattern-matching-the-gestalt-approach/184407970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seatName = df['seatName']\n",
    "HDIRegion = HDI['Region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examine how the algo matches our seatNames to the HDI region names\n",
    "HDINameSimilarity = []\n",
    "for i in seatName:\n",
    "    closestName = difflib.get_close_matches(i,HDIRegion,1,0.5)\n",
    "    HDINameSimilarity.append(closestName)\n",
    "    print(i, ' : ' ,closestName, ' Index : ', len(HDINameSimilarity) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrections : \n",
    "There are some constituencies that have more than one regions in the HDI. I'll just use the first region. We could(should) use the mean/median instead.\n",
    "\n",
    "| seatName | HDI Matched Region | Index # of List | Corrected |\n",
    "|----------|--------------------|-----------------|-----------|\n",
    "| Malir-I | ['Matiari'] | 233 | Karachi |\n",
    "| Malir-II  |  ['Matiari'] | 234 | Karachi |\n",
    "| Malir-III |  ['Matiari'] | 235 | Karachi |\n",
    "| Loralai-cum-Musa Khail-cum-Ziarat-cum-Dukki-cum-Harnai  |  [] | 255 | Loralai |\n",
    "| Dera Bugti-cum-Kohlu-cum-Barkhan-cum-Sibi-cum-Lehri  |  [] | 256 | Dera Bugti |\n",
    "| Nasirabad-cum-Kachhi-cum-Jhal Magsi  |  [] |  257 | Bolan/Kachhi |\n",
    "| Killa Abdullah  | ['Killa Saifullah'] | 260 | *missing* |\n",
    "| Mastung-cum-Shaheed Sikandarabad-cum-Kalat  |  [] |  264 | Mastung |\n",
    "| Panjgur-cum-Washuk-cum-Awaran  |  []  | 267 | Washuk |\n",
    "| Kech  |  ['Karachi']  | 268 | *missing* |\n",
    "\n",
    "#### Missing : \n",
    "| seatName | HDI Matched Region | Index # of List | Corrected |\n",
    "|----------|--------------------|-----------------|-----------|\n",
    "| Kohistan-cum-Lower Kolai Pallas Kohistan  |  []  | 10 | *missing* |\n",
    "| Tribal Area - I  |  []  |  39 | *missing* |\n",
    "| Tribal Area - II  |  []  |  40 | *missing* |\n",
    "| Tribal Area - III  |  [] |  41 | *missing* |\n",
    "| Tribal Area - IV  | []  |  42 | *missing* |\n",
    "| Tribal Area - V  | []  |   43 | *missing* |\n",
    "| Tribal Area - VI  |  []  |  44 | *missing* |\n",
    "| Tribal Area - VII  |  [] |  45 | *missing* |\n",
    "| Tribal Area - VIII  |  [] |  46 | *missing* |\n",
    "| Tribal Area - IX  |  [] |   47 | *missing* |\n",
    "| Tribal Area - X  |  []  |  48 | *missing* |\n",
    "| Tribal Area - XI  |  [] |  49 | *missing* |\n",
    "| Tribal Area - XII  |  [] |  50 | *missing* |\n",
    "| Chagai-cum-Nushki-cum-Kharan  | []  | 265 | *missing* |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDINameSimilarity[233] = ['Karachi']\n",
    "HDINameSimilarity[234] = ['Karachi']\n",
    "HDINameSimilarity[235] = ['Karachi']\n",
    "HDINameSimilarity[255] = ['Loralai']\n",
    "HDINameSimilarity[256] = ['Dera Bugti']\n",
    "HDINameSimilarity[257] = ['Bolan/Kachhi']\n",
    "HDINameSimilarity[260] = []\n",
    "HDINameSimilarity[264] = ['Mastung']\n",
    "HDINameSimilarity[267] = ['Washuk']\n",
    "HDINameSimilarity[268] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HDIRegionJoinName = []\n",
    "for i in HDINameSimilarity:\n",
    "    if len(i) == 0:\n",
    "        HDIRegionJoinName.append(np.nan)\n",
    "    else:\n",
    "        HDIRegionJoinName.append(i[0])\n",
    "\n",
    "df['HDIRegionJoinName'] = HDIRegionJoinName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cursory check on the seatNames and the HDI Regions \n",
    "df[['seatName','HDIRegionJoinName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(HDI,left_on='HDIRegionJoinName',right_on='Region',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../Data/Election_2018_NA_Results_Raw.csv',encoding='utf-8',index=False)\n",
    "dfResultsOnly.to_csv('../Data/Election_2018_NA_Results_VotingOnly.csv',encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
