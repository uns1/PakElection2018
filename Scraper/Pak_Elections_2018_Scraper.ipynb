{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from time import sleep\n",
    "from random import randint, randrange\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "header = {'User-Agent':str(ua.firefox)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I used the General Election 2018 Dashboard website to fetch URLs for each constituency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "r = requests.get('https://www.ecp.gov.pk/resultdashboard/ge2018.aspx',headers=header)\n",
    "soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "# From the dashboard page, fetch URLs for all the NA seats\n",
    "na_urls = [i.find('a')['href'][2:].replace(' ','%20')\\\n",
    "           for i in soup.find_all(name='div',attrs={'class':'card card-hover'})\\\n",
    "           if i.find('a') != None]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this page has been taken down for some reason so instead I use a list of constituency numbers and insert this into the URL that holds data for each individual constituency.\n",
    "\n",
    "We leave out NA-60 and NA-103 because elections here were postponed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a list of constituency names to insert into the URLs\n",
    "naSeats = ['NA-' + str(i) for i in np.arange(1,273) if i not in [60,103]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe = []\n",
    "count = 0\n",
    "sleep_between_requests == False\n",
    "\n",
    "for seat in naSeats:\n",
    "    url = 'https://www.ecp.gov.pk/ConstResult.aspx?Const_Id=' + seat + '&type=NA&Election_ID=10070&Election=GENERAL%20ELECTION%2025%20JUL%202018'\n",
    "    print('\\n--- Fetching HTML for Seat # : ' + str(seat))\n",
    "    r = requests.get(url,headers=header)\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        print('--- HTML retrieved. Extracting Data')\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    else:\n",
    "        print('*** Abort. HTML Status Code ' + str(r.status_code))\n",
    "        break\n",
    "    \n",
    "    # Extract seat info and result status\n",
    "    seatInfo = soup.find_all('span',{'id' : 'ContentPlaceHolder2_lblSubHeading'})[0].getText()\n",
    "    seatName = seatInfo[seatInfo.find('(') + 1 : seatInfo.find(')')]\n",
    "    seatStatus = seatInfo[seatInfo.find(')') + 1 : ].strip()\n",
    "    \n",
    "    # Extract voting statistics\n",
    "    stats = soup.find_all('table')[0]\n",
    "    registeredVoters = stats.find('span',{'id': 'ContentPlaceHolder1_lblRegVoters'}).getText()\n",
    "    votesPolled = stats.find('span',{'id': 'ContentPlaceHolder1_lblVotesPolled'}).getText()\n",
    "    validVotes = stats.find('span',{'id': 'ContentPlaceHolder1_lblValidVotes'}).getText()\n",
    "    rejectedVotes = stats.find('span',{'id': 'ContentPlaceHolder1_lblRejVotes'}).getText()\n",
    "    polledToRegisteredRatio = stats.find('span',{'id': 'ContentPlaceHolder1_lblTO'}).getText().replace('%','').strip()\n",
    "    \n",
    "    # Extract voting results\n",
    "    voteCount = soup.find_all('table')[1]\n",
    "    votingResults = []\n",
    "    for i in voteCount.find_all('tr'):\n",
    "        row = i.find_all('p')\n",
    "        if len(row) != 0:\n",
    "            candidateName = row[0].getText()\n",
    "            candidateParty = row[1].getText()\n",
    "            candidateVotes = row[2].getText()\n",
    "            votingDict = {'candidateName' : candidateName,\\\n",
    "                          'candidateParty' : candidateParty,\\\n",
    "                          'candidateVotes' : int(candidateVotes)}\n",
    "            votingResults.append(votingDict)\n",
    "        \n",
    "    data = {'seat' : seat,\\\n",
    "            'seatName' : seatName,\\\n",
    "            'seatStatus' : seatStatus,\\\n",
    "            'registeredVoters' : int(registeredVoters),\\\n",
    "            'votesPolled' : int(votesPolled),\\\n",
    "            'validVotes' : int(validVotes),\\\n",
    "            'rejectedVotes' : int(rejectedVotes),\\\n",
    "            'polledToRegRatio' : float(polledToRegisteredRatio) / 100,\\\n",
    "            'numberOfCandidates' : len(votingResults),\\\n",
    "            'votingResults' : votingResults,\n",
    "            }\n",
    "    \n",
    "    dataframe.append(data)\n",
    "    print('--- ' + seat + ' data addedd succesfully.')\n",
    "    count += 1\n",
    "    \n",
    "    if sleep_between_requests == True:\n",
    "        # Sleep for a few seconds before moving on to the next seat\n",
    "        sleep_seconds = randint(2,10)\n",
    "        print('--- Sleeping For : ', sleep_seconds, ' seconds.\\n')\n",
    "        sleep(sleep_seconds)\n",
    "    \n",
    "print('\\n--- ' + str(count) + ' seats processed.')  \n",
    "print('There should be 270 seats : ', len(dataframe) == 270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ECP website has voting results for NA-39 all wrong. For now, this is the only constituency that has faulty data on the website that I'm aware of but I'm pretty sure there are more. Let me know if you come across any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe[38]['votingResults'] = [\n",
    "    {'candidateName' : 'Muhammad Yaqoob Sheikh', 'candidateParty' : 'Pakistan Tehreek-e-Insaf', 'candidateVotes' : 5511},\n",
    "    {'candidateName' : 'Alhaj Sardar Umar Farooq Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 29},\n",
    "    {'candidateName' : 'Asmat Ullah', 'candidateParty' : 'Independent', 'candidateVotes' : 98},\n",
    "    {'candidateName' : 'Eithesham Ullah Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 5},\n",
    "    {'candidateName' : 'Faisal Karim Kundi', 'candidateParty' : 'Independent', 'candidateVotes' : 20},\n",
    "    {'candidateName' : 'Fazl ur Rehman', 'candidateParty' : 'Muttahida Majlis-e-Amal Pakistan', 'candidateVotes' : 4076},\n",
    "    {'candidateName' : 'Irfan Ullah Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 20},\n",
    "    {'candidateName' : 'Muhammad Aftab Inayat', 'candidateParty' : 'Independent', 'candidateVotes' : 105},\n",
    "    {'candidateName' : 'Muhammad Akbar Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 57},\n",
    "    {'candidateName' : 'Muhammad Amir', 'candidateParty' : 'Independent', 'candidateVotes' : 12},\n",
    "    {'candidateName' : 'Muhammad Maqbool', 'candidateParty' : 'Amun Taraqqi Party', 'candidateVotes' : 23},\n",
    "    {'candidateName' : 'Nurang Khan', 'candidateParty' : 'Pakistan Peoples Party Parliamentarians', 'candidateVotes' : 292},\n",
    "    {'candidateName' : 'Obaid Ur Rehman', 'candidateParty' : 'Independent', 'candidateVotes' : 32},\n",
    "    {'candidateName' : 'Qaizar Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 564},\n",
    "    {'candidateName' : 'Waqar Ahmad Khan', 'candidateParty' : 'Independent', 'candidateVotes' : 98},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will also retrieve voter participation rates, which is also bifurcated by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "participationResult = []\n",
    "\n",
    "r = requests.get('https://www.ecp.gov.pk/frmstats.aspx',headers=header)\n",
    "soup = BeautifulSoup(r.text, \"lxml\")\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "for i in rows[1:]: # We don't look at the first row since these are just headers.\n",
    "    row = i.find_all('td')\n",
    "    participationResult.append(\n",
    "        {\n",
    "        'seat' : row[0].getText(),\n",
    "        'femaleTurnout' : float(row[1].getText().replace(' %','')) / 100,\n",
    "        'maleTurnout' : float(row[2].getText().replace(' %','')) / 100,\n",
    "        'totalTurnout' : float(row[3].getText().replace(' %','')) / 100,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "dfParticipation = pd.DataFrame(participationResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store as a Pandas dataframe and store in a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataframe)\n",
    "df = df.merge(dfParticipation,on='seat')\n",
    "df.to_csv('../Data/Election_2018_NA_Results_Raw.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The voting results is a list of dictionaries contained in the dataframe above. For easier access, we will convert this to it's own dataframe and store it in a CSV as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultsOnlyDataframe = []\n",
    "for i in dataframe:\n",
    "    resultsDict = i['votingResults']\n",
    "    for j in resultsDict:\n",
    "        j['seat'] = i['seat']\n",
    "        j['seatName'] = i['seatName']\n",
    "        resultsOnlyDataframe.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfResultsOnly = pd.DataFrame(resultsOnlyDataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfResultsOnly.to_csv('../Data/Election_2018_NA_Results_VotingOnly.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winners & Runner Ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding margins from winners.\n",
    "\n",
    "seat = ''\n",
    "for row in dfResultsOnly.iterrows():\n",
    "    if row[1]['seat'] == seat:\n",
    "        margin = winnerVotes - row[1]['candidateVotes']\n",
    "    else:\n",
    "        winnerVotes = dfResultsOnly[dfResultsOnly['seat'] == row[1]['seat']][['candidateVotes']].max().values[0]\n",
    "        margin = winnerVotes - row[1]['candidateVotes']\n",
    "        seat = row[1]['seat']\n",
    "\n",
    "    dfResultsOnly.loc[row[0],'marginFromWinner'] = int(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Winners & Runner Ups DF & CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winnerIdx = dfResultsOnly.groupby(by='seat',)[['candidateVotes']].idxmax()\n",
    "winnerResults = dfResultsOnly.iloc[winnerIdx['candidateVotes'].values]\n",
    "\n",
    "runnerUpIdx = dfResultsOnly.groupby(by='seat')['candidateVotes'].nlargest(2).reset_index().groupby('seat').last()['level_1'].values\n",
    "runnerupResults = dfResultsOnly.iloc[runnerUpIdx]\n",
    "\n",
    "winnerResults = winnerResults.drop('marginFromWinner',axis=1)\n",
    "winnerResults = winnerResults.merge(runnerupResults[['seat','marginFromWinner']],on='seat').rename(columns={'marginFromWinner' : 'winMargin'})\n",
    "winnerResults.to_csv('../Data/Election_2018_NA_winnerResults.csv',index=False,encoding='utf-8')\n",
    "runnerupResults.to_csv('../Data/Election_2018_NA_runnerupResults.csv',index=False,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
